\documentclass[8pt,landscape]{extarticle}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{color,graphicx,overpic}
\usepackage[hidelinks]{hyperref}
\usepackage{tabularx}
\newcommand\NumCols{3}
\pdfinfo{
  /Title (formula-sheet.pdf)
  /Creator (TeX)
  /Producer (pdfTeX 1.40.0)
  /Author (Garrett Weaver)
  /Subject (SIE 530)
  /Keywords (statistics, engineering, masters, Arizona, Liu)}

% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
    { \geometry{top=.5in,left=.5in,right=.5in,bottom=.5in} }
    {\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
        {\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
        {\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
    }

% Turn off header and footer
\pagestyle{empty}

% Redefine section commands to use less space
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
\makeatother

% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print section numbers
\setcounter{secnumdepth}{0}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}

%My Environments
\newtheorem{example}[section]{Example}
% -----------------------------------------------------------------------

\begin{document}

\raggedright
%\footnotesize\usepackage{amsmath}
\begin{multicols}{\NumCols}


% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\begin{center}
     \Large{\underline{SIE 530 Formula Sheet}} \\
\end{center}

\section{Set Notation}
\hspace*{-0.2cm}\begin{tabularx}{\textwidth/\NumCols}{ l X }
Commutativity: &
\hspace*{-0.5cm}\begin{tabular}{ l }
$A \cup B = B \cup A$ \\
$ A \cap B = B \cap A$ \\
\end{tabular}\hspace*{-1cm} \\

Associativity: &
\hspace*{-0.5cm}\begin{tabular}{ l }
$A\cup (B \cup C)=(A \cup B) \cup C$ \\
$A \cap (B \cap C) = (A \cap B) \cap C$ \\
\end{tabular} \\

Distributive Laws: &
\hspace*{-0.5cm}\begin{tabular}{ l }
$A \cap(B \cup C) = (A \cap B) \cup ( A \cap C)$ \\
$ A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$ \\
\end{tabular}\\

DeMorgan's Laws: &
\hspace*{-0.5cm}\begin{tabular}{ l }
$(A \cup B)^c=A^c \cap B^c$ \\
$(A \cap B)^c=A^c\cup B^c$ \\
\end{tabular} \\
\end{tabularx}

\section{Probability Theory}

Central Tendency: sample average/mean 
$$\bar{x}=\frac{\sum\limits_{i=1}^{n} x_i}{n}$$

Scatter/dispersion: \emph{sample variance} or \emph{sample standard deviation}
$$\hat{\sigma}^2=S^2=\frac{\sum\limits_{i=1}^{n}(x_i-\bar{x})^2}{n-1};\quad\hat{\sigma}=S=\sqrt{\frac{\sum\limits_{i=1}^{n}(x_i-\bar{x})^2}{n-1}}$$

\section{Definition of Probability}
[P \(\) : \{set of all possible events\} $\rightarrow [0,1]$] 
\begin{itemize}
\item Axiom 1: For any event $A, P(A)\geq 0$ (nonnegatove).
\item Axiom 2: $P(S)=1$
\item Axiom 3: For any sequence of disjoint sets $A_1,A_2,\dots,A_n, P(A_1 \cup A_2 \cup \dots A_n)=\sum\limits_{i=1}^nP(A_i)$, where n is the total number of disjoint sets in the sequence.
\end {itemize}
\begin{itemize}
\item Properties:
\begin{itemize}
\item $P(A)=1-P(A^c);$
\item $P(\emptyset)=0$
\item $P(S)=1$
\item if $A$ and $B$ are disjoint $P(A\cup B)=0$
\item $A\subset B \rightarrow P(A)\leq (B)$
\end{itemize}
\item Additive Law of probability
\begin{itemize}
\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\end{itemize}
\end{itemize}

Independent: Two events $A$ and $B$ are said to be independent if $P(A|B)=P(A)$, $f(x,y)=f_X(x)f_Y(y); \quad \forall x,y$

\section{Counting Rules}
\begin{tabularx}{\textwidth/\NumCols}{| c | c | X |} \hline
 & Without replacement & With Replacement \\ \hline
Ordered: & $P_{k,n} = \frac{n!}{(n-k)!}$ & $n^r$ \\ \hline
Unordered: & $C_{k,n}=
\begin{pmatrix}
n \\
k
\end{pmatrix}
=\frac{n!}{k!(n-k)!}
$ & 
$
\begin{pmatrix}
n + r - 1\\
k
\end{pmatrix}$
\\ \hline
\end{tabularx}

\section{Common Sums and Integrations}
$\sum_{k=0}^\infty \frac{z^k}{k!} = e^z\,\!;$ $\sum_{k=0}^\infty k\frac{z^k}{k!} = z e^z\,\!;$
$\sum_{k=1}^\infty\frac{z^k}{k}=-ln(1-z);$ $\sum_{k=1}^\infty z^k=\frac{z}{1-z};$ $\sum_{k=1}^\infty kz^k=\frac{z}{(1-z)^2}$
$\int u(x)v'(x)dx=u(x)v(x)-\int u'(x)v(x)dx$
$\int xe^{ax}dx=\begin{pmatrix}\frac{x}{a}-\frac{1}{a^2}\end{pmatrix}e^{ax}$
$\int x^2e^{ax}dx=\begin{pmatrix}\frac{x^2}{a}-\frac{2x}{a^2}+\frac{2}{a^3}\end{pmatrix}e^{ax}$

\section{Bayes Theorem}
Let the events $A_1,A_2,\dots A_k$ be \emph{disjoint} and \emph{exhaustive} events in the sample space $S$, such that $P(A_i)>0$ and let $B$ be an event such that $P(B)>0$, then, 
$$P(A_i|B)=\frac{P(B|A_i)P(A_i)}{\sum_{j=1}^k P(B|A_i)P(A_j)}$$
$$P(A_i|B)=\frac{P(A_i \cap B)}{P(B)} = \frac{cond. \quad prob.}{law \quad of \quad total \quad prob.}$$
$$P(A|B)P(B)=P(B|A)P(A)$$
$$P(A_1|B)+P(A_2|B)+\dots P(A_k|B)=1$$
Conditional Distribution
$$f(y|x)=P(Y=y|X=x)=\frac{f_{XY}(x,y)}{f_X(x)}$$

\section{Discrete Random Variables}
\emph{Probability mass function} (pmf) of a discrete \emph{Random Variable} is given by 
$$f_X(x)=P(X=x)$$
and satisfies the following properties
\begin{enumerate}
\item $f_X(x)\geq 0; \quad \forall x$
\item $\sum\limits_{i=1}^{\infty}f(x_i)=1$
\end{enumerate}

\emph{Cumulative Distribution Function} (cdf) of a discrete \emph{Random Variable} 
$$F_X(x)=P(X\leq x)=\sum\limits_{i=1}^{x}f_X(i); \quad \forall x$$

Satisfies the following properties
\begin{enumerate}
\item $\lim\limits_{x\to-\infty}F(x)=0$ and $\lim\limits_{x\to\infty}F(x)=1$
\item $F(x)$ is a \emph{nondecreasing} function of $x$
\item $F(x)$ is \emph{right-continuous} for every number $x_0, \quad \lim_{x\downarrow x_0}F(x)=F(x_0)$
\end{enumerate}

\section{Continuous Random Variables}
The \emph{probability density function} (pdf) of a continuous \emph{Random Variable} is given by 
$$\int_{x_1}^{x_2}f_X(x)dx=P(x_1\leq X\leq x_2), \quad \forall x_1,x_2$$
And satisfies the following properties:
\begin{enumerate}
\item $f(x)\geq 0 \quad \forall x$
\item $\int_{-\infty}^{\infty}f(x)dx=1$
\end{enumerate}

The \emph{Cumulative Distribution Function}(cdf) for a continuous \emph{Random Variable} is 
$$F_X(x)=P(X \leq x) = \int_{-\infty}^{x}f_X(u)du, \quad \forall x$$
And satisifes the following property:
\begin{enumerate}
\item $\frac{\partial F_X(x)}{\partial x}=f_X(x)$ provided that $F'$ exists and $X$ is a continuous \emph{Random Variable}
\end{enumerate}

\section{Marginal Distribution}
Discrete Model:\\
$f_X(x)=\sum\limits_{y\in\Re}f_{XY}(x,y)$ and $f_Y(y)=\sum\limits_{x\in\Re}f_{XY}(x,y)$
Continuous Model:\\
$f_X(x)=\int\limits_{-\infty}^{\infty}f_{XY}(x,y)dy$ and $f_Y(y)=\int\limits_{-\infty}^{\infty}f_{XY}(x,y)dx$

\section{Expectation}
\subsection{Univariate}
$E(X)=\mu_X=\sum\limits_{x\in X} xf(x)$; 
$E(X)=\mu_X=\int\limits_{-\infty}^{\infty}xf(x)dx$ \\
\subsection{Multivariate}
$E(Y|X=x)=\mu_X=\sum\limits_{x\in X} yf(y|x)$; 
$E(Y|X=x)=\mu_X=\int\limits_{-\infty}^{\infty}yf(y|x)dx$\\
\subsection{Property}
$E(X+Y)=E(X)+E(Y)$

\section{Variance}
\subsection{Univariate}
$Var(X)=\sigma_X^2=E[(X-\mu)^2]$
$Var(X)=E(X^2)-[E(X)]^2$ \\
\subsection{Multivariate}
$Var(Y|x)=E(Y^2|x)-(E(Y|x))^2$
$Var(X)=E(Var(X|Y))+Var[E(X|Y)]$\\
\subsection{Property}
$Var(X+Y)=Var(X)+Var(Y)$

\section{Function of an RV}
\subsection{Method 1:} Let X be a random variable with pdf $f_X(x)$.\\
1st step : $F_Y(y) = P(Y\leq y)=P[r(X)\leq y]=\int_{x:r(x)\leq Y}f_X(x)dx$\\
2nd step : $f_Y(y) = \frac{dF_Y(y)}{dy}$

\subsection{Method 2:}
$f_Y(y)=\begin{cases} 
f_X(r^{-1}(y))|\frac{\partial r^{-1}(y)}{\partial y}| & y\in Y \subseteq R;\\
0 & otherwise
   \end{cases}$

\subsection{Method 3:}
$$Z=X+Y$$
$$M_z(t)=M_X(t)*M_Y(t)$$
Solve the equation, whatever PDF the product ends up looking as will be the function Z follows.

\section{Exponential Family}
$$f(x|\theta)=h(x)*c(\theta)exp\begin{pmatrix}\sum\limits_{i=1}^k w_i(\theta)t_i(x)\end{pmatrix}$$
where $h(x)\geq 0$ and $t_i(x)$ are real-valued, $c(\theta)\geq 0$ and $w_i(\theta)$ are real-valued and not dependent on x. 

\section{Moment Generating Function}
$$M_X(t)=E[e^{tX}]$$
$$M_X(t)=\int\limits_{-\infty}^{\infty}e^{tx}f_X(x)dx$$
$$M_X(t)=\sum\limits_{x}e^{tx}P(X=x)$$
Satsifies the following properties
$$M_X^{(n)}(t)=\frac{d^nM_X(t)}{dt^n}\bigg|_{t=0}$$
Also has the property:
$$E(X)=\frac{dM_X(t)}{dt}\bigg|_{t=0};\quad Var(X)=\frac{d^2M_X(t)}{dt^2}\bigg|_{t=0}$$

\section{Joint pdf/pmf of Random Sample}
Given the iid random sample $X_1, X_2,\dots X_n$
$$f(x_1, x_2,\dots x_n)=f(x_1)f(x_2)\dots f(x_n)=\prod\limits_{i=1}^n f(x_i)$$
$$f(x_1,x_2,\dots x_n|\theta)=\prod\limits_{i=1}^n f(x_i|\theta)$$

\section{Student's t-distribution}
Z-statistic:
$$T=\frac{\bar{X}-\mu}{S/\sqrt{n}}; \quad Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$$

\section{Common Distributions}

\subsection{HyperGeometric($x$)}
\begin{tabularx}{\textwidth/\NumCols}{ l X }
\emph{pmf} & ${{{K \choose k} {{N-K} \choose {n-k}}}\over {N \choose n}}$; \\
\emph{mean and variance} & $EX=n {K\over N}$; $Var X =n{K\over N}{(N-K)\over N}{N-n\over N-1}$ \\
\emph{mgf} & $\frac{{N-K \choose n} \scriptstyle{\,_2F_1(-n, -K; N - K - n + 1; e^{t}) } }{{N \choose n}}  \,\!$ \\
\end{tabularx}

\subsection{Poisson($\lambda$)}
\begin{tabularx}{\textwidth/\NumCols}{ l X }
\emph{pmf} & $P(X=x|\lambda)=\frac{e^{-\lambda}\lambda^x}{x!}$; $x=0, 1, \dots$; $0 \leq \lambda <\infty$ \\
\emph{mean and variance} & $EX=\lambda$; $Var X =\lambda$ \\
\emph{mgf} & $M_X(t)=e^{\lambda(e^t-1)}$ \\
\end{tabularx}

\subsection{Chi squared(p)}
\begin{tabularx}{\textwidth/\NumCols}{ l X }
\emph{pmf} & $f(x|p)=\frac{1}{\Gamma(p/2)2^{p/2}}x^{(p/2)-1}e^{-x/2}$; $0 \leq x < \infty$; $p=1, 2, \dots$ \\
\emph{mean and variance} & $EX = p$; $Var X = 2p$ \\
\emph{mgf} & $M_X(t)=\begin{pmatrix} \frac{1}{1-2t} \end{pmatrix}^{p/2}, \quad t < \frac{1}{2}$ \\
\end{tabularx}

\subsection{Exponential($\beta$)}
\begin{tabularx}{\textwidth/\NumCols}{ l X }
\emph{pmf} & $f(x|p)=\frac{1}{\beta}e^{-x/\beta}$; $0 \leq x < \infty$; $\beta>0$ \\
\emph{mean and variance} & $EX = \beta$; $Var X = \beta^2$ \\
\emph{mgf} & $M_X(t)= \frac{1}{1-\beta t}, \quad t < \frac{1}{\beta}$ \\
\end{tabularx}

\subsection{Gamma($x|\alpha, \beta$)}
\begin{tabularx}{\textwidth/\NumCols}{ l X }
\emph{pmf} & $f(x|\alpha, \beta)=\frac{1}{\Gamma(\alpha)\beta^{\alpha}} x^{\alpha - 1}e^{-x/\beta};$ $0 \leq x < \infty$; $\alpha\beta>0$ \\
\emph{mean and variance} & $EX = \alpha\beta$; $Var X = \alpha\beta^2$ \\
\emph{mgf} & $M_X(t)= \begin{pmatrix}\frac{1}{1-\beta t}\end{pmatrix}^{\alpha}, \quad t < \frac{1}{\beta}$ \\
\end{tabularx}

\subsection{Normal($\mu, \sigma^2$)}
\begin{tabularx}{\textwidth/\NumCols}{ l X }
\emph{pmf} & $f(x|\mu, \sigma^2)=\frac{1}{\sqrt{2\pi \sigma}}e^{-(x-\mu)^2/(2\sigma^2)}$; $-\infty < x < \infty$; $-\infty < \mu < \infty$ \\
\emph{mean and variance} & $EX = \mu$; $Var X = \sigma^2$ \\
\emph{mgf} & $M_X(t)= e^{\mu t + \sigma^2t^2/2}$ \\
\end{tabularx}

\subsection{Uniform($a, b$)}
\begin{tabularx}{\textwidth/\NumCols}{ l X }
\emph{pmf} & $f(x|a, b)=\frac{1}{b-a}$, $a \leq x \leq b$ \\
\emph{mean and variance} & $EX = \frac{b+a}{2}$; $Var X = \frac{(b-a)^2}{12}$ \\
\emph{mgf} & $M_X(t)=\frac{e^{bt}-e^{at}}{(b-a)t}$ \\
\end{tabularx}

\scriptsize
\bibliographystyle{unsrt} 
\bibliography{course-references}
\end{multicols}
\end{document}

